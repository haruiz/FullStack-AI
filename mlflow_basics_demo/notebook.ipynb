{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64a503d9-9233-450e-9f57-a15356bc4654",
   "metadata": {},
   "source": [
    "# ML lifecycle automation tools\n",
    "\n",
    "## MLflow\n",
    "\n",
    "MLflow is an open-source platform developed by Databricks that allows ML practitioners, such as data scientists and ML engineerings, to automate the complete end-to-end machine learning lifecycle using a simple and intuitive code interface. It includes tools for tracking experiments, packaging code into reproducible runs and sharing and deploying models. Its open interface design can work with any language or platform, with clients in Python and Java, and is accessible through a REST API. \n",
    "\n",
    "MLflow provides APIs for logging parameters, code versions, metrics, and artifacts when running your machine learning code and for later visualizing the results. It also provides a library of reusable components for machine learning tasks, such as pre-processing data and training models, that can be packaged into a reusable, reproducible run.\n",
    "\n",
    "In addition, MLflow integrates with a variety of machine learning libraries, including TensorFlow, PyTorch, and sci-kit-learn, allowing you to use the tools you are already familiar with while taking advantage of the advanced tracking and management capabilities of MLflow.\n",
    "\n",
    "For this post, you will need the following prerequisites:\n",
    "\n",
    "- The latest version of Docker installed in your machine. In case you don't have the latest version, please follow the instructions at the following URL: https://docs.docker.com/get-docker/.\n",
    "- Access to a bash terminal (Linux or Windows).\n",
    "- Access to a browser.\n",
    "- Python 3.5+ installed.\n",
    "- PIP installed.\n",
    "\n",
    "## Why MLflow?\n",
    "\n",
    "MLflow provides a single platform for everyday practitioners to handle the entire machine learning lifecycle, from iterating on model development to deploying it in a scalable and reliable environment that meets modern software system requirements.It facilitates the colaboration across roles and standarize the set of tools use a high level.\n",
    "\n",
    "### Getting started with Mlflow\n",
    "\n",
    "In the following code example, the Tracking API will be introduced. It would help us better understand how the MLflow API works and how it can be used to track our experiment's metrics, parameters, and artifacts during experimentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f32bb2d1-56af-47a0-97e9-9ba91b1eb4c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from mlflow import log_metric, log_param, log_artifact\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78d521d6-fb31-4262-a7e4-b439bd0ae1c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "'/home/jovyan/mlruns' does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mException\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Log a parameter (key-value pair)\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mlog_param\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mparam1\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Log a metric; metrics can be updated throughout the run\u001B[39;00m\n\u001B[1;32m      5\u001B[0m log_metric(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfoo\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/tracking/fluent.py:541\u001B[0m, in \u001B[0;36mlog_param\u001B[0;34m(key, value)\u001B[0m\n\u001B[1;32m    517\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    518\u001B[0m \u001B[38;5;124;03mLog a parameter (e.g. model hyperparameter) under the current run. If no run is active,\u001B[39;00m\n\u001B[1;32m    519\u001B[0m \u001B[38;5;124;03mthis method will create a new active run.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    538\u001B[0m \u001B[38;5;124;03m        assert value == 0.01\u001B[39;00m\n\u001B[1;32m    539\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    540\u001B[0m run_id \u001B[38;5;241m=\u001B[39m _get_or_start_run()\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mrun_id\n\u001B[0;32m--> 541\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mMlflowClient\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_param\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/tracking/client.py:742\u001B[0m, in \u001B[0;36mMlflowClient.log_param\u001B[0;34m(self, run_id, key, value)\u001B[0m\n\u001B[1;32m    689\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlog_param\u001B[39m(\u001B[38;5;28mself\u001B[39m, run_id: \u001B[38;5;28mstr\u001B[39m, key: \u001B[38;5;28mstr\u001B[39m, value: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    690\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    691\u001B[0m \u001B[38;5;124;03m    Log a parameter (e.g. model hyperparameter) against the run ID.\u001B[39;00m\n\u001B[1;32m    692\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    740\u001B[0m \u001B[38;5;124;03m        status: FINISHED\u001B[39;00m\n\u001B[1;32m    741\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 742\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tracking_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_param\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    743\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m value\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py:295\u001B[0m, in \u001B[0;36mTrackingServiceClient.log_param\u001B[0;34m(self, run_id, key, value)\u001B[0m\n\u001B[1;32m    293\u001B[0m param \u001B[38;5;241m=\u001B[39m Param(key, \u001B[38;5;28mstr\u001B[39m(value))\n\u001B[1;32m    294\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 295\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_param\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    296\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m MlflowException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    297\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m e\u001B[38;5;241m.\u001B[39merror_code \u001B[38;5;241m==\u001B[39m ErrorCode\u001B[38;5;241m.\u001B[39mName(INVALID_PARAMETER_VALUE):\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py:918\u001B[0m, in \u001B[0;36mFileStore.log_param\u001B[0;34m(self, run_id, param)\u001B[0m\n\u001B[1;32m    916\u001B[0m _validate_run_id(run_id)\n\u001B[1;32m    917\u001B[0m _validate_param(param\u001B[38;5;241m.\u001B[39mkey, param\u001B[38;5;241m.\u001B[39mvalue)\n\u001B[0;32m--> 918\u001B[0m run_info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_run_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    919\u001B[0m check_run_is_active(run_info)\n\u001B[1;32m    920\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_log_run_param(run_info, param)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py:650\u001B[0m, in \u001B[0;36mFileStore._get_run_info\u001B[0;34m(self, run_uuid)\u001B[0m\n\u001B[1;32m    646\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_run_info\u001B[39m(\u001B[38;5;28mself\u001B[39m, run_uuid):\n\u001B[1;32m    647\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    648\u001B[0m \u001B[38;5;124;03m    Note: Will get both active and deleted runs.\u001B[39;00m\n\u001B[1;32m    649\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 650\u001B[0m     exp_id, run_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_find_run_root\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_uuid\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    651\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m run_dir \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    652\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\n\u001B[1;32m    653\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRun \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m not found\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m run_uuid, databricks_pb2\u001B[38;5;241m.\u001B[39mRESOURCE_DOES_NOT_EXIST\n\u001B[1;32m    654\u001B[0m         )\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py:550\u001B[0m, in \u001B[0;36mFileStore._find_run_root\u001B[0;34m(self, run_uuid)\u001B[0m\n\u001B[1;32m    548\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_find_run_root\u001B[39m(\u001B[38;5;28mself\u001B[39m, run_uuid):\n\u001B[1;32m    549\u001B[0m     _validate_run_id(run_uuid)\n\u001B[0;32m--> 550\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_root_dir\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    551\u001B[0m     all_experiments \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_active_experiments(\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_deleted_experiments(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    552\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m experiment_dir \u001B[38;5;129;01min\u001B[39;00m all_experiments:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py:173\u001B[0m, in \u001B[0;36mFileStore._check_root_dir\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    169\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;124;03mRun checks before running directory operations.\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m exists(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot_directory):\n\u001B[0;32m--> 173\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m does not exist.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot_directory)\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_directory(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot_directory):\n\u001B[1;32m    175\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is not a directory.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot_directory)\n",
      "\u001B[0;31mException\u001B[0m: '/home/jovyan/mlruns' does not exist."
     ]
    }
   ],
   "source": [
    "# Log a parameter (key-value pair)\n",
    "log_param(\"param1\", 5)\n",
    "\n",
    "# Log a metric; metrics can be updated throughout the run\n",
    "log_metric(\"foo\", 1)\n",
    "log_metric(\"foo\", 2)\n",
    "log_metric(\"foo\", 3)\n",
    "\n",
    "# Log an artifact (output file)\n",
    "with open(\"output.txt\", \"w\") as f:\n",
    "    f.write(\"Hello world!\")\n",
    "log_artifact(\"output.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5572d992-285c-4289-92f7-6e974299228c",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can observe that a new folder named `mlruns` was created along with some files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e365769-26c3-41a6-b184-479a0a0b09f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat /etc/*-release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7b714f-aa99-42dc-803b-13493201b0c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tree mlruns -L 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db461fa7-40cc-4025-aba6-5535cb3f78fe",
   "metadata": {},
   "source": [
    "The mlruns folder is the default root directory for storing experiment runs and artifacts in the MLflow tracking component. The folder structure of the mlruns directory consists of multiple subdirectories, one for each run in your experiment.\n",
    "\n",
    "Each run subdirectory is named after a unique run ID and contains the following files and directories:\n",
    "\n",
    "- **meta.yaml:** A YAML file that contains metadata about the run, such as the run's status, start time, end time, and user-defined tags and parameters.\n",
    "- **params:** A directory that contains YAML files for each parameter used in the run. Each file is named after the parameter name and contains its value.\n",
    "- **tags:** A directory that contains YAML files for each tag applied to the run. Each file is named after the tag name and contains its value.\n",
    "- **artifacts:** A directory that contains files or directories generated as artifacts during the run. The contents of the artifacts directory are determined by the user and may include models, data files, plots, or other outputs.\n",
    "\n",
    "This structure allows for easy navigation of experiment runs, as well as efficient storage and retrieval of the metadata, parameters, tags, and artifacts associated with each run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c25e98b-4c84-46f1-9138-1a2d73e855ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Viewing the Tracking UI\n",
    "\n",
    "By default, wherever you run your program, the tracking API writes data into files into an mlruns directory. You can then run MLflow’s Tracking UI to visualize your experiments metadata and information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d68bf0f-c291-4958-a3e1-6a348af8314e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mlflow server -h 0.0.0.0 -p 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc4e66a-5152-4910-990a-d69008f364b4",
   "metadata": {},
   "source": [
    "The experiments' metadata, runs information, parameters, and metrics can also be accessed programmatically by using the MLFlow client interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070e2e7a-8ee7-4df9-8368-a052ea92d81b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "\n",
    "# list of experiments\n",
    "experiments_list = client.search_experiments() # returns a list of mlflow.entities.Experiment\n",
    "for experiment in experiments_list:\n",
    "    print(experiment.name, experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa4ad1-ee58-4483-8b43-2c32ee7de49e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list of runs\n",
    "\n",
    "runs_list = client.search_runs(\"Default\") # returns a list of mlflow.entities.Experiment\n",
    "for run in runs_list:\n",
    "    print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e45e6e-3982-4be5-be5c-6e5e7817e82b",
   "metadata": {},
   "source": [
    "Let's review another example where we explore further the mlflow API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab278858-2521-471d-874b-0f7748a464bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create experiment\n",
    "experiment_name = \"Social NLP Experiments\"\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if experiment:\n",
    "    experiment_id = experiment.experiment_id\n",
    "else:\n",
    "    experiment_id = mlflow.create_experiment(\"Social NLP Experiments\")\n",
    "    \n",
    "# ends the currently active run, if any, taking an optional run status.\n",
    "mlflow.end_run()\n",
    "\n",
    "# start a run\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name=\"run1\") as run1:\n",
    "    mlflow.log_metric(\"m\", 1.55)\n",
    "    mlflow.set_tag(\"s.release\", \"1.1.0-RC\")\n",
    "    \n",
    "    \n",
    "# start another run\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name=\"run2\") as run2:\n",
    "    mlflow.log_metric(\"m\", 2.50)\n",
    "    mlflow.set_tag(\"s.release\", \"1.2.0-GA\")\n",
    "    \n",
    "# Search all runs under experiment id and order them by\n",
    "# descending value of the metric 'm'\n",
    "client = MlflowClient()\n",
    "runs = client.search_runs(experiment_id, order_by=[\"metrics.m DESC\"])\n",
    "for r in runs:\n",
    "    print(f\"run_id: {r.info.run_id}\")\n",
    "    print(f\"lifecycle_stage: {r.info.lifecycle_stage}\")\n",
    "    print(f\"metrics: {r.data.metrics}\")\n",
    "\n",
    "    # Exclude mlflow system tags\n",
    "    tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    print(r\"tags: {tags}\")\n",
    "\n",
    "\n",
    "# Delete the first run\n",
    "client.delete_run(run_id=run1.info.run_id)\n",
    "\n",
    "# Search only deleted runs under the experiment id and use a case insensitive pattern\n",
    "# in the filter_string for the tag.\n",
    "filter_string = \"tags.s.release ILIKE '%rc%'\"\n",
    "runs = client.search_runs(experiment_id, run_view_type=ViewType.DELETED_ONLY,\n",
    "                            filter_string=filter_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638a406b-05e0-4efa-854c-6d90a9a711b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_best_run(experiment_id, metric):\n",
    "    # Connect to mflow using the default connection\n",
    "    client = MlflowClient()\n",
    "    \n",
    "    # Get all the runs for the experiment\n",
    "    runs = client.search_runs(experiment_id)\n",
    "    \n",
    "    # Find the run with the highest accuracy metric\n",
    "    best_run = None\n",
    "    best_metric_value = 0\n",
    "    for run in runs:\n",
    "        metric_value = run.data.metrics[metric]\n",
    "        if metric_value > best_metric_value:\n",
    "            best_metric_value = metric_value\n",
    "            best_run = run\n",
    "    # Return the best run\n",
    "    return best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27857c56-b526-4e51-a30c-824817195ddb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_best_run(experiment_id, metric=\"m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03793839-026a-415f-baf4-083ac9067b8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Machine Learning Workflow\n",
    "\n",
    "Machine learning requires experimenting with a wide range of datasets, data preparation steps, and algorithms to build a model that maximizes some target metric. Once you have built a model, you also need to deploy it to a production system, monitor its performance, and continuously retrain it on new data and compare with alternative models.\n",
    "\n",
    "Being productive with machine learning can therefore be challenging for several reasons:\n",
    "\n",
    "- **It’s difficult to keep track of experiments.** When you are just working with files on your laptop, or with an interactive notebook, how do you tell which data, code and parameters went into getting a particular result?\n",
    "- **It’s difficult to reproduce code.** Even if you have meticulously tracked the code versions and parameters, you need to capture the whole environment (for example, library dependencies) to get the same result again. This is especially challenging if you want another data scientist to use your code, or if you want to run the same code at scale on another platform (for example, in the cloud).\n",
    "- **There’s no standard way to package and deploy models.** Every data science team comes up with its own approach for each ML library that it uses, and the link between a model and the code and parameters that produced it is often lost.\n",
    "\n",
    "Moreover, although individual ML libraries provide solutions to some of these problems (for example, model serving), to get the best result you usually want to try multiple ML libraries. MLflow lets you train, reuse, and deploy models with any library and package them into reproducible steps that other data scientists can use as a “black box,” without even having to know which library you are using.\n",
    "\n",
    "## MLflow Components\n",
    "MLflow provides three components to help manage the ML workflow:\n",
    "\n",
    "- **MLflow Tracking** is an API and UI for logging parameters, code versions, metrics, and output files when running your machine learning code and for later visualizing the results. You can use MLflow Tracking in any environment (for example, a standalone script or a notebook) to log results to local files or to a server, then compare multiple runs. Teams can also use it to compare results from different users.\n",
    "\n",
    "- **MLflow Projects** are a standard format for **packaging reusable data science code**. Each project is simply a directory with code or a Git repository, and uses a descriptor file or simply convention to specify its dependencies and how to run the code. For example, projects can contain a conda.yaml file for specifying a Python Conda environment. When you use the MLflow Tracking API in a Project, MLflow automatically remembers the project version executed (for example, Git commit) and any parameters. You can easily run existing MLflow Projects from GitHub or your own Git repository, and chain them into multi-step workflows.\n",
    "\n",
    "- **MLflow Models** offer a convention for packaging machine learning models in multiple flavors, and a variety of tools to help you deploy them. Each Model is saved as a directory containing arbitrary files and a descriptor file that lists several “flavors” the model can be used in. For example, a TensorFlow model can be loaded as a TensorFlow DAG, or as a Python function to apply to input data. MLflow provides tools to deploy many common model types to diverse platforms: for example, any model supporting the “Python function” flavor can be deployed to a Docker-based REST server, to cloud platforms such as Azure ML and AWS SageMaker, and as a user-defined function in Apache Spark for batch and streaming inference. If you output MLflow Models using the Tracking API, MLflow will also automatically remember which Project and run they came from.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
