{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64a503d9-9233-450e-9f57-a15356bc4654",
   "metadata": {},
   "source": [
    "# ML lifecycle automation tools\n",
    "\n",
    "# MLflow\n",
    "\n",
    "MLflow is an open-source platform that allows users to automate the complete machine learning lifecycle. It includes tools for tracking experiments, packaging code into reproducible runs and sharing and deploying models. It is based on an open interface design, can work with any language or platform, with clients in Python and Java, and is accessible through a REST API. \n",
    "\n",
    "MLflow provides APIs for logging parameters, code versions, metrics, and artifacts when running your machine learning code and for later visualizing the results. It also provides a library of reusable components for machine learning tasks, such as pre-processing data and training models, that can be packaged into a reusable, reproducible run.\n",
    "\n",
    "In addition, MLflow integrates with a variety of machine learning libraries, including TensorFlow, PyTorch, and sci-kit-learn, allowing you to use the tools you are already familiar with while taking advantage of the advanced tracking and management capabilities of MLflow.\n",
    "\n",
    "For this chapter, you will need the following prerequisites:\n",
    "\n",
    "- The latest version of Docker installed in your machine. In case you don't have the latest version, please follow the instructions at the following URL: https://docs.docker.com/get-docker/.\n",
    "- Access to a bash terminal (Linux or Windows).\n",
    "- Access to a browser.\n",
    "- Python 3.5+ installed.\n",
    "- PIP installed.\n",
    "\n",
    "# Why MLflow?\n",
    "\n",
    "MLflow provides a single platform for everyday practitioners to handle the entire machine learning lifecycle, from iterating on model development to deploying it in a scalable and reliable environment that meets modern software system requirements.It facilitates the colaboration across roles and standarize the set of tools use a high level.\n",
    "\n",
    "\n",
    "# Getting started with Mlflow\n",
    "\n",
    "# Low Level API\n",
    "\n",
    "### Using the Tracking API\n",
    "\n",
    "The MLflow Tracking API lets you log metrics and artifacts (files) from your data science code and see a history of your runs. You can try it out by writing a simple Python script as follows (this example is also included in example/quickstart/test.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78d521d6-fb31-4262-a7e4-b439bd0ae1c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from mlflow import log_metric, log_param, log_artifact\n",
    "\n",
    "# Log a parameter (key-value pair)\n",
    "log_param(\"param1\", 5)\n",
    "\n",
    "# Log a metric; metrics can be updated throughout the run\n",
    "log_metric(\"foo\", 1)\n",
    "log_metric(\"foo\", 2)\n",
    "log_metric(\"foo\", 3)\n",
    "\n",
    "# Log an artifact (output file)\n",
    "with open(\"output.txt\", \"w\") as f:\n",
    "    f.write(\"Hello world!\")\n",
    "log_artifact(\"output.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5572d992-285c-4289-92f7-6e974299228c",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can observe that a new folder named `mlruns` has been created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e365769-26c3-41a6-b184-479a0a0b09f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISTRIB_ID=Ubuntu\n",
      "DISTRIB_RELEASE=22.04\n",
      "DISTRIB_CODENAME=jammy\n",
      "DISTRIB_DESCRIPTION=\"Ubuntu 22.04.1 LTS\"\n",
      "PRETTY_NAME=\"Ubuntu 22.04.1 LTS\"\n",
      "NAME=\"Ubuntu\"\n",
      "VERSION_ID=\"22.04\"\n",
      "VERSION=\"22.04.1 LTS (Jammy Jellyfish)\"\n",
      "VERSION_CODENAME=jammy\n",
      "ID=ubuntu\n",
      "ID_LIKE=debian\n",
      "HOME_URL=\"https://www.ubuntu.com/\"\n",
      "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
      "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
      "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
      "UBUNTU_CODENAME=jammy\n"
     ]
    }
   ],
   "source": [
    "!cat /etc/*-release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c7b714f-aa99-42dc-803b-13493201b0c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[01;34mmlruns\u001B[0m\n",
      "└── \u001B[01;34m0\u001B[0m\n",
      "    ├── \u001B[01;34m2ea55bd70a9d406991c47c77a2c4b44f\u001B[0m\n",
      "    │   ├── \u001B[01;34martifacts\u001B[0m\n",
      "    │   │   └── \u001B[00moutput.txt\u001B[0m\n",
      "    │   ├── \u001B[00mmeta.yaml\u001B[0m\n",
      "    │   ├── \u001B[01;34mmetrics\u001B[0m\n",
      "    │   │   └── \u001B[00mfoo\u001B[0m\n",
      "    │   ├── \u001B[01;34mparams\u001B[0m\n",
      "    │   │   └── \u001B[00mparam1\u001B[0m\n",
      "    │   └── \u001B[01;34mtags\u001B[0m\n",
      "    │       ├── \u001B[00mmlflow.runName\u001B[0m\n",
      "    │       ├── \u001B[00mmlflow.source.name\u001B[0m\n",
      "    │       ├── \u001B[00mmlflow.source.type\u001B[0m\n",
      "    │       └── \u001B[00mmlflow.user\u001B[0m\n",
      "    └── \u001B[00mmeta.yaml\u001B[0m\n",
      "\n",
      "6 directories, 9 files\n"
     ]
    }
   ],
   "source": [
    "!tree mlruns -L 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db461fa7-40cc-4025-aba6-5535cb3f78fe",
   "metadata": {},
   "source": [
    "The mlruns folder is the default root directory for storing experiment runs and artifacts in the MLflow tracking component. The folder structure of the mlruns directory consists of multiple subdirectories, one for each run in your experiment.\n",
    "\n",
    "Each run subdirectory is named after a unique run ID and contains the following files and directories:\n",
    "\n",
    "- **meta.yaml:** A YAML file that contains metadata about the run, such as the run's status, start time, end time, and user-defined tags and parameters.\n",
    "- **params:** A directory that contains YAML files for each parameter used in the run. Each file is named after the parameter name and contains its value.\n",
    "- **tags:** A directory that contains YAML files for each tag applied to the run. Each file is named after the tag name and contains its value.\n",
    "- **artifacts:** A directory that contains files or directories generated as artifacts during the run. The contents of the artifacts directory are determined by the user and may include models, data files, plots, or other outputs.\n",
    "\n",
    "This structure allows for easy navigation of experiment runs, as well as efficient storage and retrieval of the metadata, parameters, tags, and artifacts associated with each run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c25e98b-4c84-46f1-9138-1a2d73e855ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Viewing the Tracking UI\n",
    "\n",
    "By default, wherever you run your program, the tracking API writes data into files into an mlruns directory. You can then run MLflow’s Tracking UI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d68bf0f-c291-4958-a3e1-6a348af8314e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mlflow server -h 0.0.0.0 -p 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61696d22-e9cd-4a60-a702-325300e639e0",
   "metadata": {},
   "source": [
    "## Using the Client API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "070e2e7a-8ee7-4df9-8368-a052ea92d81b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default <Experiment: artifact_location='file:///home/jovyan/mlruns/0', creation_time=1675919900130, experiment_id='0', last_update_time=1675919900130, lifecycle_stage='active', name='Default', tags={}>\n"
     ]
    }
   ],
   "source": [
    "from  mlflow.tracking import MlflowClient\n",
    "\n",
    "# we can access the experiments that has been created\n",
    "client = MlflowClient()\n",
    "experiments_list = client.search_experiments() # returns a list of mlflow.entities.Experiment\n",
    "for experiment in experiments_list:\n",
    "    print(experiment.name, experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7daa4ad1-ee58-4483-8b43-2c32ee7de49e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runs_list = client.search_runs(\"Default\") # returns a list of mlflow.entities.Experiment\n",
    "for run in runs_list:\n",
    "    print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5289effd-2fba-4a8d-ad47-65d9d8ed9f8b",
   "metadata": {},
   "source": [
    "## Running MLflow Projects\n",
    "\n",
    "MLflow allows you to package code and its dependencies as a project that can be run in a reproducible fashion on other data. Each project includes its code and a MLproject file that defines its dependencies (for example, Python environment) as well as what commands can be run into the project and what arguments they take.\n",
    "\n",
    "You can easily run existing projects with the mlflow run command, which runs a project from either a local directory or a GitHub URI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "800b1b55-e62a-4def-aa21-00aedab81387",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023/02/09 00:32:07 INFO mlflow.projects.utils: === Fetching project from https://github.com/mlflow/mlflow-example.git into /tmp/tmp4z4_ap6e ===\n",
      "2023/02/09 00:32:09 INFO mlflow.projects.utils: Fetched 'master' branch\n",
      "2023/02/09 00:32:10 INFO mlflow.utils.conda: === Creating conda environment mlflow-2b6b69a3ea30872171ff71aee564367746fae613 ===\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... ^C\n"
     ]
    }
   ],
   "source": [
    "!mlflow run https://github.com/mlflow/mlflow-example.git -P alpha=5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e45e6e-3982-4be5-be5c-6e5e7817e82b",
   "metadata": {},
   "source": [
    "## Advance example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab278858-2521-471d-874b-0f7748a464bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "\n",
    "experiment_name = \"Social NLP Experiments\"\n",
    "try:\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    experiment_id = experiment.experiment_id\n",
    "except mlflow.exceptions.MlflowException as e:\n",
    "    experiment_id = mlflow.create_experiment(\"Social NLP Experiments\")\n",
    "    \n",
    "mlflow.end_run()\n",
    "\n",
    "# start a run\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name=\"run1\") as run1:\n",
    "    mlflow.log_metric(\"m\", 1.55)\n",
    "    mlflow.set_tag(\"s.release\", \"1.1.0-RC\")\n",
    "    \n",
    "    \n",
    "# start run 2\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name=\"run2\") as run2:\n",
    "    mlflow.log_metric(\"m\", 2.50)\n",
    "    mlflow.set_tag(\"s.release\", \"1.2.0-GA\")\n",
    "    \n",
    "# Search all runs under experiment id and order them by\n",
    "# descending value of the metric 'm'\n",
    "client = MlflowClient()\n",
    "runs = client.search_runs(experiment_id, order_by=[\"metrics.m DESC\"])\n",
    "for r in runs:\n",
    "    print(\"run_id: {}\".format(r.info.run_id))\n",
    "    print(\"lifecycle_stage: {}\".format(r.info.lifecycle_stage))\n",
    "    print(\"metrics: {}\".format(r.data.metrics))\n",
    "\n",
    "    # Exclude mlflow system tags\n",
    "    tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    print(\"tags: {}\".format(tags))\n",
    "\n",
    "\n",
    "# Delete the first run\n",
    "client.delete_run(run_id=run1.info.run_id)\n",
    "\n",
    "# Search only deleted runs under the experiment id and use a case insensitive pattern\n",
    "# in the filter_string for the tag.\n",
    "filter_string = \"tags.s.release ILIKE '%rc%'\"\n",
    "runs = client.search_runs(experiment_id, run_view_type=ViewType.DELETED_ONLY,\n",
    "                            filter_string=filter_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "638a406b-05e0-4efa-854c-6d90a9a711b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_best_run(experiment_id, metric):\n",
    "    # Connect to mflow using the default connection\n",
    "    client = MlflowClient()\n",
    "    \n",
    "    # Get all the runs for the experiment\n",
    "    runs = client.search_runs(experiment_id)\n",
    "    \n",
    "    # Find the run with the highest accuracy metric\n",
    "    best_run = None\n",
    "    best_metric_value = 0\n",
    "    for run in runs:\n",
    "        metric_value = run.data.metrics[metric]\n",
    "        if metric_value > best_metric_value:\n",
    "            best_metric_value = metric_value\n",
    "            best_run = run\n",
    "    # Return the best run\n",
    "    return best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27857c56-b526-4e51-a30c-824817195ddb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Run: data=<RunData: metrics={'m': 2.5}, params={}, tags={'mlflow.runName': 'run2',\n",
       " 'mlflow.source.name': '/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py',\n",
       " 'mlflow.source.type': 'LOCAL',\n",
       " 'mlflow.user': 'jovyan',\n",
       " 's.release': '1.2.0-GA'}>, info=<RunInfo: artifact_uri='file:///home/jovyan/mlruns/851752001971950812/862ae94ace5b41e1a760079150fd2179/artifacts', end_time=1675906147567, experiment_id='851752001971950812', lifecycle_stage='active', run_id='862ae94ace5b41e1a760079150fd2179', run_name='run2', run_uuid='862ae94ace5b41e1a760079150fd2179', start_time=1675906147524, status='FINISHED', user_id='jovyan'>>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_run(experiment_id, metric=\"m\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
